{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikishkaaa/ML-Course/blob/main/%D0%92%D1%81%D1%82%D1%83%D0%BF_%D0%B4%D0%BE_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B8%D1%85_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 1. Логістична регресія з нуля.**\n",
        "\n",
        "Будемо крок за кроком будувати модель лог регресії з нуля для передбачення, чи буде врожай більше за 80 яблук (задача подібна до лекційної, але на класифікацію).\n",
        "\n",
        "Давайте нагадаємо основні формули для логістичної регресії.\n",
        "\n",
        "### Функція гіпотези - обчислення передбачення у логістичній регресії:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\sigma(x W^T + b) = \\frac{1}{1 + e^{-(x W^T + b)}}\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ \\hat{y} $ — це ймовірність \"позитивного\" класу.\n",
        "- $ x $ — це вектор (або матриця для набору прикладів) вхідних даних.\n",
        "- $ W $ — це вектор (або матриця) вагових коефіцієнтів моделі.\n",
        "- $ b $ — це зміщення (bias).\n",
        "- $ \\sigma(z) $ — це сигмоїдна функція активації.\n",
        "\n",
        "### Як обчислюється сигмоїдна функція:\n",
        "\n",
        "Сигмоїдна функція $ \\sigma(z) $ має вигляд:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Ця функція перетворює будь-яке дійсне значення $ z $ в інтервал від 0 до 1, що дозволяє інтерпретувати вихід як ймовірність для логістичної регресії.\n",
        "\n",
        "### Формула функції втрат для логістичної регресії (бінарна крос-ентропія):\n",
        "\n",
        "Функція втрат крос-ентропії оцінює, наскільки добре модель передбачає класи, порівнюючи передбачені ймовірності $ \\hat{y} $ із справжніми мітками $ y $. Формула наступна:\n",
        "\n",
        "$$\n",
        "L(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ y $ — це справжнє значення (мітка класу, 0 або 1).\n",
        "- $ \\hat{y} $ — це передбачене значення (ймовірність).\n",
        "\n"
      ],
      "metadata": {
        "id": "lbLHTNfSclli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\n",
        "Тут вже наведений код для ініціювання набору даних в форматі numpy. Перетворіть `inputs`, `targets` на `torch` тензори. Виведіть результат на екран."
      ],
      "metadata": {
        "id": "GtOYB-RHfc_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "3BNXSR-VdYKQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QLKZ77x4v_-v"
      },
      "outputs": [],
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "id": "KjoeaDrk6fO7",
        "outputId": "3874d41b-8a52-4276-bd1c-cc8577c0548b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ініціюйте ваги `w`, `b` для моделі логістичної регресії потрібної форми зважаючи на розмірності даних випадковими значеннями з нормального розподілу. Лишаю тут код для фіксації `random_seed`."
      ],
      "metadata": {
        "id": "iKzbJKfOgGV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)"
      ],
      "metadata": {
        "id": "aXhKw6Tdj1-d",
        "outputId": "340861fa-42fa-4a3a-cd2f-b9184f541060",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6704090d10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn(1, 3, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "eApcB7eb6h9o",
        "outputId": "2044c804-33e5-45ed-a0f7-ae508b9daa6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6614, 0.2669, 0.0617]], requires_grad=True)\n",
            "tensor([0.6213], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Напишіть функцію `model`, яка буде обчислювати функцію гіпотези в логістичній регресії і дозволяти робити передбачення на основі введеного рядка даних і коефіцієнтів в змінних `w`, `b`.\n",
        "\n",
        "  **Важливий момент**, що функція `model` робить обчислення на `torch.tensors`, тож для математичних обчислень використовуємо фукнціонал `torch`, наприклад:\n",
        "  - обчсилення $e^x$: `torch.exp(x)`\n",
        "  - обчсилення $log(x)$: `torch.log(x)`\n",
        "  - обчислення середнього значення вектору `x`: `torch.mean(x)`\n",
        "\n",
        "  Використайте функцію `model` для обчислення передбачень з поточними значеннями `w`, `b`.Виведіть результат обчислень на екран.\n",
        "\n",
        "  Проаналізуйте передбачення. Чи не викликають вони у вас підозр? І якщо викликають, то чим це може бути зумовлено?"
      ],
      "metadata": {
        "id": "nYGxNGTaf5s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(data, w, b):\n",
        "  temp = -(data @ w.T +b)\n",
        "  return 1/(1+ torch.exp(-temp))"
      ],
      "metadata": {
        "id": "pSz2j4Fh6jBv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model(inputs, w, b)"
      ],
      "metadata": {
        "id": "sh5mPfQuVsQw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "id": "c5TCkk-WZwtl",
        "outputId": "d2eba7fb-7fc8-435e-a5c1-c51d927c8fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.9871e-31],\n",
              "        [4.7579e-39],\n",
              "        [0.0000e+00],\n",
              "        [2.8692e-36],\n",
              "        [8.0943e-34]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок: всі значення передбачились як позитивний клас, це може бути зумовлено вагами, так як ми їх встановлюємо рандомно"
      ],
      "metadata": {
        "id": "9Ok87NF3YqWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Напишіть функцію `binary_cross_entropy`, яка приймає на вхід передбачення моделі `predicted_probs` та справжні мітки в даних `true_labels` і обчислює значення втрат (loss)  за формулою бінарної крос-ентропії для кожного екземпляра та вертає середні втрати по всьому набору даних.\n",
        "  Використайте функцію `binary_cross_entropy` для обчислення втрат для поточних передбачень моделі."
      ],
      "metadata": {
        "id": "O2AGM0Mb2yHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(predicted_probs, true_labels):\n",
        "    epsilon = 1e-10 # Small value to avoid problem with log(0)\n",
        "    loss = - (true_labels * torch.log(predicted_probs + epsilon) + (1 - true_labels) * torch.log(1 - predicted_probs + epsilon))\n",
        "    return torch.mean(loss)"
      ],
      "metadata": {
        "id": "ekkP8at2Xa-o"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = binary_cross_entropy(predicted, targets)\n",
        "print(\"Середнє значення втрат:\", loss)"
      ],
      "metadata": {
        "id": "Q3lC_o4YXglg",
        "outputId": "493ce26e-fa9f-4e07-ae8a-04ca3d28c9d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Середнє значення втрат: tensor(13.8155, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Зробіть зворотнє поширення помилки і виведіть градієнти за параметрами `w`, `b`. Проаналізуйте їх значення. Як гадаєте, чому вони саме такі?"
      ],
      "metadata": {
        "id": "ZFKpQxdHi1__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "YAbXUNSJ6mCl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Градієнти вагів\n",
        "print(w)\n",
        "print(w.grad)"
      ],
      "metadata": {
        "id": "xRLqmy9neNfy",
        "outputId": "048a042a-e3bc-4b6c-f7d4-34c82e5c3974",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6614, 0.2669, 0.0617]], requires_grad=True)\n",
            "tensor([[nan, nan, nan]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradients for bias\n",
        "print(b)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "id": "Ge4io4zjeU88",
        "outputId": "664b374e-edaf-4f81-c944-6fd5610e163b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6213], requires_grad=True)\n",
            "tensor([nan])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Що сталось?**\n",
        "\n",
        "В цій задачі, коли ми ініціювали значення випадковими значеннями з нормального розподілу, насправді ці значення не були дуже гарними стартовими значеннями і привели до того, що градієнти стали дуже малими або навіть рівними нулю (це призводить до того, що градієнти \"зникають\"), і відповідно при оновленні ваг у нас не буде нічого змінюватись. Це називається `gradient vanishing`. Це відбувається через **насичення сигмоїдної функції активації.**\n",
        "\n",
        "У нашій задачі ми використовуємо сигмоїдну функцію активації, яка має такий вигляд:\n",
        "\n",
        "   $$\n",
        "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "   $$\n",
        "\n",
        "\n",
        "Коли значення $z$ дуже велике або дуже мале, сигмоїдна функція починає \"насичуватись\". Це означає, що для великих позитивних $z$ сигмоїда наближається до 1, а для великих негативних — до 0. В цих діапазонах градієнти починають стрімко зменшуватись і наближаються до нуля (бо градієнт - це похідна, похідна на проміжку функції, де вона паралельна осі ОХ, дорівнює 0), що робить оновлення ваг неможливим.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/27889vaegp.png)\n",
        "\n",
        "У логістичній регресії $ z = x \\cdot w + b $. Якщо ваги $w, b$ - великі, значення $z$ також буде великим, і сигмоїда перейде в насичену область, де градієнти дуже малі.\n",
        "\n",
        "Саме це сталося в нашій задачі, де великі випадкові значення ваг викликали насичення сигмоїдної функції. Це в свою чергу призводить до того, що під час зворотного поширення помилки (backpropagation) модель оновлює ваги дуже повільно або зовсім не оновлює. Це називається проблемою **зникнення градієнтів** (gradient vanishing problem).\n",
        "\n",
        "**Що ж робити?**\n",
        "Ініціювати ваги маленькими значеннями навколо нуля. Наприклад ми можемо просто в існуючій ініціалізації ваги розділити на 1000. Можна також використати інший спосіб ініціалізації вагів - інформація про це [тут](https://www.geeksforgeeks.org/initialize-weights-in-pytorch/).\n",
        "\n",
        "Як це робити - показую нижче. **Виконайте код та знову обчисліть передбачення, лосс і виведіть градієнти.**\n",
        "\n",
        "А я пишу пояснення, чому просто не зробити\n",
        "\n",
        "```\n",
        "w = torch.randn(1, 3, requires_grad=True)/1000\n",
        "b = torch.randn(1, requires_grad=True)/1000\n",
        "```\n",
        "\n",
        "Нам потрібно, аби тензори вагів були листовими (leaf tensors).\n",
        "\n",
        "1. **Що таке листовий тензор**\n",
        "Листовий тензор — це тензор, який був створений користувачем безпосередньо і з якого починається обчислювальний граф. Якщо такий тензор має `requires_grad=True`, PyTorch буде відслідковувати всі операції, виконані над ним, щоб правильно обчислювати градієнти під час навчання.\n",
        "\n",
        "2. **Чому ми використовуємо `w.data` замість звичайних операцій**\n",
        "Якщо ми просто виконали б операції, такі як `(w - 0.5) / 100`, ми б отримали **новий тензор**, який вже не був би листовим тензором, оскільки ці операції створюють **новий** тензор, а не модифікують існуючий.\n",
        "\n",
        "  Проте, щоб залишити наші тензори ваги `w` та зміщення `b` листовими і продовжити можливість відстеження градієнтів під час тренування, ми використовуємо атрибут `.data`. Цей атрибут дозволяє **виконувати операції in-place (прямо на існуючому тензорі)** без зміни самого об'єкта тензора. Отже, тензор залишається листовим, і PyTorch може коректно обчислювати його градієнти.\n",
        "\n",
        "3. **Чому важливо залишити тензор листовим**\n",
        "Якщо тензор більше не є листовим (наприклад, через проведення операцій, що створюють нові тензори), ви не зможете отримати градієнти за допомогою `w.grad` чи `b.grad` після виклику `loss.backward()`. Це може призвести до втрати можливості оновлення параметрів під час тренування моделі. В нашому випадку ми хочемо, щоб тензори `w` та `b` накопичували градієнти, тому вони повинні залишатись листовими.\n",
        "\n",
        "**Висновок:**\n",
        "Ми використовуємо `.data`, щоб виконати операції зміни значень на ваги і зміщення **in-place**, залишаючи їх листовими тензорами, які можуть накопичувати градієнти під час навчання. Це дозволяє коректно працювати механізму зворотного поширення помилки (backpropagation) і оновлювати ваги моделі."
      ],
      "metadata": {
        "id": "nDN1t1RujQsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Виконайте код та знову обчисліть передбачення, лосс і знайдіть градієнти та виведіть всі ці тензори на екран."
      ],
      "metadata": {
        "id": "rOPSQyttpVjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)\n",
        "w = torch.randn(1, 3, requires_grad=True)  # Листовий тензор\n",
        "b = torch.randn(1, requires_grad=True)     # Листовий тензор\n",
        "\n",
        "# in-place операції\n",
        "w.data = w.data / 1000\n",
        "b.data = b.data / 1000"
      ],
      "metadata": {
        "id": "-EBOJ3tsnRaD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(inputs, w, b)\n",
        "loss = binary_cross_entropy(predictions, targets)\n",
        "print(\"Середнє значення втрат:\", loss)\n",
        "\n",
        "loss.backward()\n",
        "print(w)\n",
        "print(w.grad)\n",
        "\n",
        "print(b)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "id": "-JwXiSpX6orh",
        "outputId": "baee37dd-7beb-4cb5-80b6-9f1988c3022c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Середнє значення втрат: tensor(0.7051, grad_fn=<MeanBackward0>)\n",
            "tensor([[6.6135e-04, 2.6692e-04, 6.1677e-05]], requires_grad=True)\n",
            "tensor([[ 8.9583, 22.6147, 12.3318]])\n",
            "tensor([0.0006], requires_grad=True)\n",
            "tensor([0.1206])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Напишіть алгоритм градієнтного спуску, який буде навчати модель з використанням написаних раніше функцій і виконуючи оновлення ваг. Алгоритм має включати наступні кроки:\n",
        "\n",
        "  1. Генерація прогнозів\n",
        "  2. Обчислення втрат\n",
        "  3. Обчислення градієнтів (gradients) loss-фукнції відносно ваг і зсувів\n",
        "  4. Налаштування ваг шляхом віднімання невеликої величини, пропорційної градієнту (`learning_rate` домножений на градієнт)\n",
        "  5. Скидання градієнтів на нуль\n",
        "\n",
        "Виконайте градієнтний спуск протягом 1000 епох, обчисліть фінальні передбачення і проаналізуйте, чи вони точні?"
      ],
      "metadata": {
        "id": "RCdi44IT334o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Тренування протягом 1000 епох\n",
        "for i in range(1000):\n",
        "    preds = model(inputs, w, b)\n",
        "    loss = binary_cross_entropy(preds, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()"
      ],
      "metadata": {
        "id": "mObHPyE06qsO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs, w, b)\n",
        "loss = binary_cross_entropy(preds, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "Ao3EZcEQf2Sa",
        "outputId": "98f521d6-7260-4dc1-afdb-c6c1abcd3e53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.3348, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(targets), display(preds)"
      ],
      "metadata": {
        "id": "ldLJxx0lf6BF",
        "outputId": "16661e25-ba00-43a2-daa3-bf2b761c5091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[0.5773],\n",
              "        [0.6689],\n",
              "        [0.9114],\n",
              "        [0.1603],\n",
              "        [0.8663]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок: досить добре модель робить передбачення. Якщо поставити theselhold =0.6, то всі екзмляри будуть правильно класифіковані"
      ],
      "metadata": {
        "id": "21MhOW9lgKzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 2. Створення лог регресії з використанням функціоналу `torch.nn`.**\n",
        "\n",
        "Давайте повторно реалізуємо ту ж модель, використовуючи деякі вбудовані функції та класи з PyTorch.\n",
        "\n",
        "Даних у нас буде побільше - тож, визначаємо нові масиви."
      ],
      "metadata": {
        "id": "fuRhlyF9qAia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ],
      "metadata": {
        "id": "IX8Bhm74rV4M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Завантажте вхідні дані та мітки в PyTorch тензори та з них створіть датасет, який поєднує вхідні дані з мітками, використовуючи клас `TensorDataset`. Виведіть перші 3 елементи в датасеті.\n",
        "\n"
      ],
      "metadata": {
        "id": "7X2dV30KtAPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "\n",
        "data = TensorDataset(inputs, targets)\n",
        "data[:3]"
      ],
      "metadata": {
        "id": "chrvMfBs6vjo",
        "outputId": "9faff1b5-cc45-4dff-dba9-6c6cd6fe0af1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]),\n",
              " tensor([[0.],\n",
              "         [1.],\n",
              "         [1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Визначте data loader з класом **DataLoader** для підготовленого датасету `train_ds`, встановіть розмір батчу на 5 та увімкніть перемішування даних для ефективного навчання моделі. Виведіть перший елемент в дата лоадері."
      ],
      "metadata": {
        "id": "4nMFaa8suOd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "train_dl = DataLoader(data, batch_size, shuffle=True)\n",
        "next(iter(train_dl))"
      ],
      "metadata": {
        "id": "ZCsRo5Mx6wEI",
        "outputId": "f38a6e48-73ce-4ce0-f2d0-e4990c913fd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [102.,  43.,  37.],\n",
              "         [ 69.,  96.,  70.],\n",
              "         [102.,  43.,  37.]]),\n",
              " tensor([[0.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [0.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Створіть клас `LogReg` для логістичної регресії, наслідуючи модуль `torch.nn.Module` за прикладом в лекції (в частині про FeedForward мережі).\n",
        "\n",
        "  У нас модель складається з лінійної комбінації вхідних значень і застосування фукнції сигмоїда. Тож, нейромережа буде складатись з лінійного шару `nn.Linear` і використання активації `nn.Sigmid`. У створеному класі мають бути реалізовані методи `__init__` з ініціалізацією шарів і метод `forward` для виконання прямого проходу моделі через лінійний шар і функцію активації.\n",
        "\n",
        "  Створіть екземпляр класу `LogReg` в змінній `model`."
      ],
      "metadata": {
        "id": "ymcQOo_hum6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Визначаємо модель\n",
        "class LogReg(nn.Module):\n",
        "    # Ініціалізуємо шари\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 1)  # Лінійний шар\n",
        "        self.act = nn.Sigmoid()        # Функція активації\n",
        "\n",
        "    # Виконуємо обчислення\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "# Створюємо екземпляр моделі\n",
        "model = LogReg()"
      ],
      "metadata": {
        "id": "EyAwhTBW6xxz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Задайте оптимізатор `Stockastic Gradient Descent` в змінній `opt` для навчання моделі логістичної регресії. А також визначіть в змінній `loss` функцію втрат `binary_cross_entropy` з модуля `torch.nn.functional` для обчислення втрат моделі. Обчисліть втрати для поточних передбачень і міток, а потім виведіть їх. Зробіть висновок, чи моделі вдалось навчитись?"
      ],
      "metadata": {
        "id": "RflV7xeVyoJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.SGD(model.parameters(), 1e-5)\n",
        "loss_fn = F.binary_cross_entropy\n",
        "loss = loss_fn(model(inputs), targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "3QCATPU_6yfa",
        "outputId": "63f1b192-4700-4780-fd88-3741f76e05b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7.6312, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Візьміть з лекції функцію для тренування моделі з відстеженням значень втрат і навчіть щойно визначену модель на 1000 епохах. Виведіть після цього графік зміни loss, фінальні передбачення і значення таргетів."
      ],
      "metadata": {
        "id": "ch-WrYnKzMzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Модифікована функцію fit для відстеження втрат\n",
        "def fit_return_loss(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        # Ініціалізуємо акумулятор для втрат\n",
        "        total_loss = 0\n",
        "\n",
        "        for xb, yb in train_dl:\n",
        "            # Генеруємо передбачення\n",
        "            pred = model(xb)\n",
        "\n",
        "            # Обчислюємо втрати\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "            # Виконуємо градієнтний спуск\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # Накопичуємо втрати\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Обчислюємо середні втрати для епохи\n",
        "        avg_loss = total_loss / len(train_dl)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "        # Виводимо підсумок епохи\n",
        "        if (epoch + 1) % 100 == 0:\n",
        "          print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "    return losses"
      ],
      "metadata": {
        "id": "cEHQH9qE626k"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:3]"
      ],
      "metadata": {
        "id": "oMrw7Ugnmg9r",
        "outputId": "0efa2aac-57a7-438f-bb56-7ec38b284b00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]),\n",
              " tensor([[0.],\n",
              "         [1.],\n",
              "         [1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = fit_return_loss(1000, model, loss_fn, opt, train_dl)"
      ],
      "metadata": {
        "id": "p1YW8PXDkvKj",
        "outputId": "1ccbfb86-5013-466b-c5d5-2f18a136928e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 4.5353\n",
            "Epoch [200/1000], Loss: 3.6974\n",
            "Epoch [300/1000], Loss: 2.8748\n",
            "Epoch [400/1000], Loss: 2.0854\n",
            "Epoch [500/1000], Loss: 1.3831\n",
            "Epoch [600/1000], Loss: 0.8436\n",
            "Epoch [700/1000], Loss: 0.5492\n",
            "Epoch [800/1000], Loss: 0.4263\n",
            "Epoch [900/1000], Loss: 0.3627\n",
            "Epoch [1000/1000], Loss: 0.3297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FWSwt6V6oDxw",
        "outputId": "6d53c44b-13d8-4cb0-c949-b71b5f290398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "preds"
      ],
      "metadata": {
        "id": "nj2bz9RioRQ6",
        "outputId": "c0fd286f-e105-48ce-df79-52dc20352871",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5729],\n",
              "        [0.6791],\n",
              "        [0.9026],\n",
              "        [0.1569],\n",
              "        [0.8761],\n",
              "        [0.5729],\n",
              "        [0.6791],\n",
              "        [0.9026],\n",
              "        [0.1569],\n",
              "        [0.8761],\n",
              "        [0.5729],\n",
              "        [0.6791],\n",
              "        [0.9026],\n",
              "        [0.1569],\n",
              "        [0.8761]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "id": "OXpyM6VwoTHk",
        "outputId": "24688ab2-33ef-45d1-f9d7-93df533d6ff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок: модель навчилась"
      ],
      "metadata": {
        "id": "wbuoKjLgo9kE"
      }
    }
  ]
}